{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06f769c",
   "metadata": {},
   "source": [
    "## Pipeline Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779af472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from enum import Enum\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from mistralai import Mistral, DocumentURLChunk, ImageURLChunk, ResponseFormat\n",
    "from mistralai.extra import response_format_from_pydantic_model\n",
    "from IPython.display import display, Markdown\n",
    "from typing import List, Union\n",
    "import base64\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from murf import Murf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed2616",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d05d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar a API da Mistral e configurar modelos\n",
    "api_key_mistral = os.environ[\"MISTRAL_API_KEY\"]\n",
    "\n",
    "api_key_murf = os.environ[\"MURF_API_KEY\"]\n",
    "\n",
    "model_large = \"mistral-large-latest\"\n",
    "model_ocr = \"mistral-ocr-latest\"\n",
    "\n",
    "client_mistral = Mistral(api_key=api_key_mistral)\n",
    "\n",
    "client_murf = Murf(api_key=api_key_murf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a323f",
   "metadata": {},
   "source": [
    "## OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c2c6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OCR salvo em ocr_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8750/2398212864.py:31: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(ocr_response.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    }
   ],
   "source": [
    "def encode_pdf(pdf_path):\n",
    "    \"\"\"Encode the pdf to base64.\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as pdf_file:\n",
    "            return base64.b64encode(pdf_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {pdf_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:  # Added general exception handling\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to your pdf\n",
    "pdf_path = \"/home/isi-tic/Data_2/Bitlearns/PDF/integração metodologias agéis, Kanban e Scrum.pptx.pdf\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_pdf = encode_pdf(pdf_path)\n",
    "\n",
    "ocr_response = client_mistral.ocr.process(\n",
    "    model=\"mistral-ocr-latest\",\n",
    "    document={\n",
    "        \"type\": \"document_url\",\n",
    "        \"document_url\": f\"data:application/pdf;base64,{base64_pdf}\" \n",
    "    },\n",
    "    include_image_base64=False\n",
    ")\n",
    "\n",
    "\n",
    "# Salvar OCR em JSON\n",
    "with open(\"ocr_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ocr_response.dict(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ OCR salvo em ocr_output.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f672f7d",
   "metadata": {},
   "source": [
    "## ROTEIRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Roteiro do podcast salvo em roteiro_podcast.txt\n"
     ]
    }
   ],
   "source": [
    "# Ler OCR salvo\n",
    "with open(\"ocr_output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ocr_data = json.load(f)\n",
    "\n",
    "# Converter para string (para enviar ao chat)\n",
    "ocr_text = json.dumps(ocr_data, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Criar roteiro para podcast\n",
    "podcast_response = client_mistral.chat.complete(\n",
    "    model=model_large,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Você é um roteirista profissional de aulas. Sua tarefa é criar um resumo do texto enviado que seja envolvente, bem estruturado e explicativo.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Transforme o conteúdo a seguir em um resumo corrido, sem tópicos ou subtítulos,\n",
    "com menos de 2800 caracteres (incluindo espaços). \n",
    "Essa é uma restrição obrigatória — NUNCA ultrapasse o limite.\n",
    "Aborde todo o assunto apresentado de forma clara e interessante, mas de forma concisa.\n",
    "\n",
    "Responda SOMENTE com o texto final, sem observações, títulos ou introdução extra.\n",
    "\n",
    "Texto de referência extraído do OCR:\n",
    "{ocr_text}\n",
    "\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "# Extrair texto do roteiro\n",
    "roteiro_podcast = podcast_response.choices[0].message.content\n",
    "\n",
    "# Salvar em arquivo\n",
    "with open(\"roteiro_podcast.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(roteiro_podcast)\n",
    "\n",
    "print(\"✅ Roteiro do podcast salvo em roteiro_podcast.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e602f",
   "metadata": {},
   "source": [
    "## AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2b96a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://murf.ai/user-upload/one-day-temp/6a115083-0ea7-4b92-a2f8-d4c69b4ef22e.wav?response-cache-control=max-age%3D604801&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250814T000000Z&X-Amz-SignedHeaders=host&X-Amz-Expires=259200&X-Amz-Credential=AKIA27M5532DYKBCJICE%2F20250814%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Signature=cbae90fbc8cba2be29eb8509459d56c2c2bb4e54a8c0a84993e15d436f2ce4a1\n",
      "✅ Áudio do podcast salvo em podcast_final.mp3\n"
     ]
    }
   ],
   "source": [
    "# Ler roteiro do podcast gerado\n",
    "with open(\"roteiro_podcast.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    roteiro_texto = f.read()\n",
    "\n",
    "response = client_murf.text_to_speech.generate(\n",
    "  text = roteiro_texto,\n",
    "  voice_id = \"pt-BR-isadora\",\n",
    "  multi_native_locale =\"pt-BR\"\n",
    ")\n",
    "\n",
    "print(response.audio_file)\n",
    "\n",
    "# Decodificar Base64 para bytes\n",
    "audio_bytes = base64.b64decode(response.audio_file)\n",
    "\n",
    "# Salvar o áudio em arquivo\n",
    "with open(\"podcast_final.mp3\", \"wb\") as audio_file:\n",
    "    audio_file.write(audio_bytes)\n",
    "\n",
    "print(\"✅ Áudio do podcast salvo em podcast_final.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv11 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
